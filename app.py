import streamlit as st
import os
import sys

# ============================================
# 1. C·∫§U H√åNH TRANG WEB (PH·∫¢I ƒê·ªÇ ƒê·∫¶U TI√äN)
# ============================================
st.set_page_config(
    page_title="ICS Assistant - Tr·ª£ l√Ω An ninh m·∫°ng",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# 2. C·∫§U H√åNH KEY & M√îI TR∆Ø·ªúNG
# ============================================
KEY_GOOGLE_MOI = "" 
KEY_GROQ_CUA_BAN = ""

os.environ["GOOGLE_API_KEY"] = KEY_GOOGLE_MOI
GROQ_API_KEY = KEY_GROQ_CUA_BAN

sys.stdout.reconfigure(encoding='utf-8')
os.environ["PYTHONIOENCODING"] = "utf-8"

# ============================================
# 3. CUSTOM CSS
# ============================================
st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* Bong b√≥ng chat tr√°i/ph·∫£i */
    .stChatMessage { border-radius: 15px; padding: 10px 15px; margin-bottom: 12px; display: flex !important; width: fit-content !important; max-width: 80% !important; }
    div[data-testid="stChatMessage"]:has(div[aria-label="chat message by user"]) { margin-left: auto !important; flex-direction: row-reverse !important; background-color: #DCF8C6 !important; border: 1px solid #c3e6cb !important; }
    div[data-testid="stChatMessage"]:has(div[aria-label="chat message by assistant"]) { margin-right: auto !important; background-color: #F0F2F5 !important; border: 1px solid #d1d5db !important; }
    div[data-testid="chatAvatarIcon-user"], div[data-testid="chatAvatarIcon-assistant"] { display: none; }

    /* ƒê·ªãnh d·∫°ng Sidebar */
    .sidebar-section { font-size: 1rem; font-weight: bold; color: #1E3A8A; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #ddd; padding-bottom: 5px; }
    .status-text { color: #10B981; font-weight: bold; font-size: 0.9rem; }
</style>
""", unsafe_allow_html=True)

# ============================================
# 4. X·ª¨ L√ù LOGIC AI
# ============================================
try:
    from langchain_community.document_loaders import Docx2txtLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    from langchain_groq import ChatGroq
    from langchain_core.prompts import ChatPromptTemplate
except ImportError:
    st.error("‚ùå Thi·∫øu th∆∞ vi·ªán! Vui l√≤ng ch·∫°y: pip install -r requirements.txt")
    st.stop()

@st.cache_resource
def load_and_process_data():
    file_path = "data/input.docx"
    if not os.path.exists(file_path):
        return None
    loader = Docx2txtLoader(file_path)
    docs = loader.load()
    splits = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=KEY_GOOGLE_MOI, transport="rest")
    return FAISS.from_documents(splits, embeddings)

with st.spinner("üîÑ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng b·∫£o m·∫≠t ICS..."):
    try:
        vectorstore = load_and_process_data()
    except Exception as e:
        st.error(f"‚ùå L·ªói k·∫øt n·ªëi AI: {e}")
        st.stop()

if vectorstore is None:
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu 'data/input.docx'")
    st.stop()

retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
llm = ChatGroq(temperature=0, model_name="llama-3.3-70b-versatile", api_key=GROQ_API_KEY)

# ============================================
# 5. GIAO DI·ªÜN CH√çNH (ƒê√É S·ª¨A ƒê·ªîI)
# ============================================

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/9004/9004869.png", width=70)
    st.markdown("### **H·ªÜ TH·ªêNG ICS**")
    
    # 1. Tr·∫°ng th√°i h·ªá th·ªëng
    #st.markdown('<p class="sidebar-section">‚ö° Tr·∫°ng th√°i</p>', unsafe_allow_html=True)
    #st.markdown("üü¢ <span class='status-text'>AI SOC: Ho·∫°t ƒë·ªông</span>", unsafe_allow_html=True)
    #st.caption("C·∫≠p nh·∫≠t d·ªØ li·ªáu: 20/01/2026")

    # 2. Th√¥ng tin c√¥ng ty
    st.markdown('<p class="sidebar-section">üè¢ V·ªÅ ch√∫ng t√¥i</p>', unsafe_allow_html=True)
    st.info("**C√¥ng ty CP An ninh M·∫°ng Qu·ªëc t·∫ø (ICS)**\n\nL√† ƒë∆°n v·ªã ti√™n phong trong lƒ©nh v·ª±c an ninh m·∫°ng t·∫°i Vi·ªát Nam v√† khu v·ª±c, chuy√™n cung c·∫•p c√°c gi·∫£i ph√°p b·∫£o m·∫≠t to√†n di·ªán cho th·ªùi ƒë·∫°i c√¥ng ngh·ªá s·ªë.")

    # 3. M·∫°ng l∆∞·ªõi vƒÉn ph√≤ng
    with st.expander("üìç ƒê·ªãa ƒëi·ªÉm vƒÉn ph√≤ng"):
        st.write("**H√† N·ªôi:**TT3-5 Khu ƒë√¥ th·ªã ƒê·∫°i Kim m·ªõi, ƒê·ªãnh C√¥ng, H√† N·ªôi.")
    

    # 4. Th√¥ng tin li√™n h·ªá
    st.markdown('<p class="sidebar-section">üìû H·ªó tr·ª£ k·ªπ thu·∫≠t</p>', unsafe_allow_html=True)
    st.markdown("**Hotline:** 0707.806.860")

    st.markdown("**Website:** [icss.com.vn](www.icss.com.vn)")

    # 5. N√∫t ch·ª©c nƒÉng
    st.markdown("---")
    if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ Chat"):
        st.session_state.messages = [{"role": "assistant", "content": "H·ªôi tho·∫°i ƒë√£ ƒë∆∞·ª£c l√†m m·ªõi. T√¥i h·ªó tr·ª£ ƒë∆∞·ª£c g√¨ cho b·∫°n?"}]
        st.rerun()

# --- HEADER TRANG CH√çNH ---
col_h1, col_h2 = st.columns([1, 8])
with col_h1:
    st.markdown("## üõ°Ô∏è")
with col_h2:
    st.title("Tr·ª£ l√Ω ·∫£o ICS")
    st.write("*H·ªá th·ªëng tra c·ª©u gi·∫£i ph√°p v√† quy tr√¨nh l√†m vi·ªác c·ªßa c√¥ng ty")



# --- CHAT UI ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω n·ªôi b·ªô c·ªßa ICS. T√¥i h·ªó tr·ª£ g√¨ cho b·∫°n."}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi v·ªÅ ICS t·∫°i ƒë√¢y..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    try:
        relevant_docs = retriever.invoke(prompt)
        context = "\n\n".join([d.page_content for d in relevant_docs])
        
        sys_prompt = ChatPromptTemplate.from_template(
            """B·∫°n l√† tr·ª£ l√Ω ·∫£o n·ªôi b·ªô c·ªßa c√¥ng ty ICS. 
            Nhi·ªám v·ª• c·ªßa b·∫°n l√† CH·ªà tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.

            QUY T·∫ÆC:
            1. N·∫øu kh√¥ng li√™n quan ƒë·∫øn c√¥ng ty ICS, tr·∫£ l·ªùi: "Xin l·ªói, c√¢u h·ªèi n·∫±m ngo√†i ph·∫°m vi h·ªó tr·ª£ c·ªßa t√¥i. T√¥i ch·ªâ h·ªó tr·ª£ th√¥ng tin n·ªôi b·ªô ICS."
            2. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát chuy√™n nghi·ªáp, ng·∫Øn g·ªçn.
            
            CONTEXT: {context}
            C√ÇU H·ªéI: {question}"""
        )
        
        chain = sys_prompt | llm
        response = chain.invoke({"context": context, "question": prompt})
        
        with st.chat_message("assistant"):
            st.markdown(response.content)
        st.session_state.messages.append({"role": "assistant", "content": response.content})

    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")